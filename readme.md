# ü©∫ Sabudh Healthcare Assistant ‚Äì RAG Chatbot

> **Ask questions in plain English, get grounded answers with citations.**  
> A domain-specific Retrieval-Augmented Generation (RAG) chatbot built for Sabudh‚Äôs healthcare handbooks, institutional policies, and educational material.

---

## üåü Key Features

- üîç **Domain-Aware Q&A:** Ask healthcare and policy questions in natural language and get answers grounded in Sabudh‚Äôs own documents.  
- üìö **Retrieval‚ÄëAugmented Generation:** Combines dense semantic search (FAISS) with a large language model to minimize hallucinations.  
- üìé **Source-Cited Responses:** Every answer comes with citation chips linking back to the exact document chunks used.  
- ‚öôÔ∏è **Configurable RAG Pipeline:** Tune chunk size, overlap, and top‚Äëk retrieval without changing core code.  
- üåê **Clean Web UI:** Responsive chat interface with a simple landing dashboard for quick onboarding.  
- üöÄ **Production‚ÄëReady Architecture:** Modular FastAPI backend, separate ingestion and indexing flow, and clear environment-based configuration.

---

## üß± Tech Stack Breakdown

| Layer      | Tools & Frameworks                                    |
|-----------|--------------------------------------------------------|
| Frontend  | HTML5, CSS3, Vanilla JS                                |
| Backend   | Python, FastAPI, Uvicorn                               |
| NLP / RAG | SentenceTransformers (`all-MiniLM-L6-v2`), FAISS, LLM (Gemini) |
| Data      | PDF handbooks, policies, course notes (local files)    |
| Config    | `.env` (API keys, model settings, index paths)         |

---

## üó∫Ô∏è Project Layout

> High-level overview of the most important files and folders.

| Path / File        | Description                                                   |
|--------------------|---------------------------------------------------------------|
| `app.py`           | FastAPI application entrypoint (routes, startup hooks)       |
| `chatbot/`         | Core RAG logic: embeddings, retrieval, prompt construction   |
| `ingestion/`       | PDF parsing, cleaning, chunking, corpus build scripts        |
| `index/`           | FAISS index build/load utilities                             |
| `data/`            | Source documents (PDFs / processed text, usually .gitignored)|
| `static/`          | CSS, JavaScript, and images for the web UI                   |
| `templates/`       | HTML templates for landing page and chat interface           |
| `requirements.txt` | Python dependencies                                          |
| `README.md`        | You are here                                                 |

If you want to see the big picture, check the diagrams in the repo:

- `image/system.png` ‚Äì High-level system architecture  
- `image/igestion.png` ‚Äì PDF ingestion and indexing pipeline  
- `image/qa_flow.png` ‚Äì Question ‚Üí Answer sequence in the RAG pipeline  
- `image/retrival.png` ‚Äì Retrieval accuracy by category  
- `image/latency.png` ‚Äì Latency breakdown by component

---

## ‚öôÔ∏è Getting Started
### 1Ô∏è‚É£ Clone the repository
git clone https://github.com/<your-username>/Healthcare-Ai-Chatbot.git
cd Healthcare-Ai-Chatbot

### 2Ô∏è‚É£ Set up a virtual environment

python -m venv .venv

Windows
.venv\Scripts\activate

macOS / Linux
source .venv/bin/activate

### 3Ô∏è‚É£ Install dependencies

pip install -r requirements.txt

### 4Ô∏è‚É£ Configure environment variables

Create a `.env` file in the project root:

GEMINI_API_KEY=your_gemini_api_key_here

EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

TOP_K=3

CHUNK_SIZE=1000

CHUNK_OVERLAP=200
FAISS_INDEX_PATH=./index/faiss.index

### 5Ô∏è‚É£ Build the corpus and FAISS index
python ingestion/build_corpus.py # parses PDFs, cleans text, creates chunks
python index/build_faiss_index.py # embeds chunks and builds the FAISS index

> Run these again whenever you add or modify documents in `data/`.

### 6Ô∏è‚É£ Run the application

uvicorn app:app --reload

Open your browser at `http://127.0.0.1:8000` and start chatting.

---

## üìä Evaluation Snapshot

### Retrieval Performance

The assistant was evaluated on a labelled test set of 23 queries:

- **Overall retrieval accuracy:** ~87%  
- **By category:**
  - Symptoms ‚Äì 87.5%  
  - Treatments ‚Äì 85.7%  
  - Policies ‚Äì 100%  
  - Educational ‚Äì 66.7%

Policies perform best because they are concise and well-structured, while educational questions often require multi‚Äëstep reasoning across multiple sections.

### Latency

Measured end‚Äëto‚Äëend from request to answer:

- **P50:** ~1.85 s  
- **P95:** ~2.55 s  
- **P99:** ~3.25 s  

Embedding + FAISS retrieval account for a few milliseconds; **LLM generation is the dominant cost**, suggesting that optimisation efforts should focus there (streaming, caching, smaller models).

---

## üß™ RAG Configuration Highlights

Some key findings from sensitivity analysis:

- **Chunk size:**  
  - 500 chars ‚Üí lower accuracy (fragmented context)  
  - **1000 chars ‚Üí best accuracy (~87%)**  
  - 2000 chars ‚Üí more context, but more noise and longer prompts  

- **Top‚Äëk retrieval:**  
  - k = 1 ‚Üí misses relevant context  
  - **k = 3 ‚Üí best trade‚Äëoff of accuracy vs token usage**  
  - k = 5 ‚Üí slight accuracy gain but more prompt bloat

---

## ‚öñÔ∏è Limitations & Responsible Use

- ‚ùó The assistant is **not a doctor** and must **not** be used for diagnosis or emergency decisions.  
- Answers are bounded by the **quality and coverage of the ingested corpus**.  
- The LLM can still make mistakes; critical decisions require human review.  
- The UI should always display a disclaimer and offer a clear way for users to report incorrect or harmful answers.

---

## üöß Roadmap

Planned / potential improvements:

- üîÑ Continuous corpus updates with new clinical and educational material  
- üß† Hybrid retrieval (BM25 + dense) and re-ranking for complex queries  
- üëç Feedback loop in the UI (thumbs up/down + comments) feeding into evaluation  
- üìâ Lower latency via smaller local LLMs or streaming responses  
- üìà Admin analytics dashboard to track usage, accuracy, and latency over time

---

## üôå Acknowledgements

This project was developed as part of the **Sabudh Passion Project**.  
Thanks to mentors, faculty, and the Sabudh Foundation for guidance, infrastructure, and access to institutional documents.

---

> üí° **Contributions welcome!**  
> Found a bug, have an idea, or want to extend the assistant?  
> Open an issue or submit a pull request and help improve the next iteration.


